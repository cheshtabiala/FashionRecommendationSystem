{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing import image                                #Helps to parse the image\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D \n",
    "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img('Data/Sample/Shoes.jpg',target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 46.,  51.,  36.],\n",
       "        [ 46.,  51.,  36.],\n",
       "        [ 46.,  51.,  36.],\n",
       "        ...,\n",
       "        [188., 187., 208.],\n",
       "        [188., 187., 208.],\n",
       "        [188., 187., 208.]],\n",
       "\n",
       "       [[ 37.,  42.,  26.],\n",
       "        [ 37.,  42.,  26.],\n",
       "        [ 37.,  42.,  26.],\n",
       "        ...,\n",
       "        [188., 187., 208.],\n",
       "        [188., 187., 208.],\n",
       "        [188., 187., 208.]],\n",
       "\n",
       "       [[ 35.,  39.,  24.],\n",
       "        [ 35.,  39.,  24.],\n",
       "        [ 35.,  39.,  24.],\n",
       "        ...,\n",
       "        [188., 187., 208.],\n",
       "        [188., 187., 208.],\n",
       "        [188., 187., 208.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[202., 214., 239.],\n",
       "        [202., 214., 239.],\n",
       "        [202., 214., 239.],\n",
       "        ...,\n",
       "        [148., 122., 126.],\n",
       "        [153., 127., 131.],\n",
       "        [149., 123., 128.]],\n",
       "\n",
       "       [[202., 214., 239.],\n",
       "        [202., 214., 239.],\n",
       "        [202., 214., 239.],\n",
       "        ...,\n",
       "        [150., 125., 129.],\n",
       "        [143., 118., 122.],\n",
       "        [139., 113., 117.]],\n",
       "\n",
       "       [[202., 214., 239.],\n",
       "        [202., 214., 239.],\n",
       "        [202., 214., 239.],\n",
       "        ...,\n",
       "        [139., 113., 117.],\n",
       "        [148., 122., 126.],\n",
       "        [158., 133., 137.]]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array = image.img_to_array(img)\n",
    "img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array.shape     # 3 in output implies RGB Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converting the image as keras workes on batches of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "expanded_img_array = np.expand_dims(img_array,axis=0)\n",
    "print(expanded_img_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(weights='imagenet',include_top=False,input_shape=(224,224,3))\n",
    "model.trainable = False\n",
    "model = tensorflow.keras.Sequential([model,GlobalMaxPooling2D()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### preprocess_input converts the input into the format which ResNet50 requires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[-67.939    , -65.779    , -77.68     ],\n",
       "         [-67.939    , -65.779    , -77.68     ],\n",
       "         [-67.939    , -65.779    , -77.68     ],\n",
       "         ...,\n",
       "         [104.061    ,  70.221    ,  64.32     ],\n",
       "         [104.061    ,  70.221    ,  64.32     ],\n",
       "         [104.061    ,  70.221    ,  64.32     ]],\n",
       "\n",
       "        [[-77.939    , -74.779    , -86.68     ],\n",
       "         [-77.939    , -74.779    , -86.68     ],\n",
       "         [-77.939    , -74.779    , -86.68     ],\n",
       "         ...,\n",
       "         [104.061    ,  70.221    ,  64.32     ],\n",
       "         [104.061    ,  70.221    ,  64.32     ],\n",
       "         [104.061    ,  70.221    ,  64.32     ]],\n",
       "\n",
       "        [[-79.939    , -77.779    , -88.68     ],\n",
       "         [-79.939    , -77.779    , -88.68     ],\n",
       "         [-79.939    , -77.779    , -88.68     ],\n",
       "         ...,\n",
       "         [104.061    ,  70.221    ,  64.32     ],\n",
       "         [104.061    ,  70.221    ,  64.32     ],\n",
       "         [104.061    ,  70.221    ,  64.32     ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[135.061    ,  97.221    ,  78.32     ],\n",
       "         [135.061    ,  97.221    ,  78.32     ],\n",
       "         [135.061    ,  97.221    ,  78.32     ],\n",
       "         ...,\n",
       "         [ 22.060997 ,   5.2210007,  24.32     ],\n",
       "         [ 27.060997 ,  10.221001 ,  29.32     ],\n",
       "         [ 24.060997 ,   6.2210007,  25.32     ]],\n",
       "\n",
       "        [[135.061    ,  97.221    ,  78.32     ],\n",
       "         [135.061    ,  97.221    ,  78.32     ],\n",
       "         [135.061    ,  97.221    ,  78.32     ],\n",
       "         ...,\n",
       "         [ 25.060997 ,   8.221001 ,  26.32     ],\n",
       "         [ 18.060997 ,   1.2210007,  19.32     ],\n",
       "         [ 13.060997 ,  -3.7789993,  15.32     ]],\n",
       "\n",
       "        [[135.061    ,  97.221    ,  78.32     ],\n",
       "         [135.061    ,  97.221    ,  78.32     ],\n",
       "         [135.061    ,  97.221    ,  78.32     ],\n",
       "         ...,\n",
       "         [ 13.060997 ,  -3.7789993,  15.32     ],\n",
       "         [ 22.060997 ,   5.2210007,  24.32     ],\n",
       "         [ 33.060997 ,  16.221    ,  34.32     ]]]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_img = preprocess_input(expanded_img_array)\n",
    "print(preprocessed_img.shape)\n",
    "preprocessed_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Giving the preprocessed output to resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4.1819544 , 16.685442  ,  5.689307  , ...,  1.2253141 ,\n",
       "         0.75266314,  9.596607  ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(preprocessed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 2048)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(preprocessed_img).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Above ouput implies we have got the embeddings value for the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2048,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting into 1D\n",
    "model.predict(preprocessed_img).flatten().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalizing - Bringing the value in range 0 - 1 by dividing each value by the L2 norm of the entire embedding value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Calculating L2\n",
    "       Basically L2 is square root of sum of squares of all the values (values obtained after prediction, \n",
    "       i.e model.predict(preprocessed_img)\n",
    "       array([[ 2.8066926, 20.916512 ,  2.2597926, ...,  4.2524285, 15.173178 , 16.647434 ]], dtype=float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "322.3872"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "norm(model.predict(preprocessed_img).flatten())     # It gives us L2 norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "322.3872"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.dot(model.predict(preprocessed_img).flatten(),model.predict(preprocessed_img).flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalizing, see the result is in 0 to 1 range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.01297184, 0.05175591, 0.01764743, ..., 0.00380075, 0.00233466,\n",
       "       0.02976733], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(preprocessed_img).flatten()/norm(model.predict(preprocessed_img).flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
